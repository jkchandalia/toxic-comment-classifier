{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EelRausYhfmf"
   },
   "source": [
    "# About this Notebook\n",
    "\n",
    "The goal of this notebook is to build a DL classifier to find toxic comments. The data has been taken from a series of Kaggle competitions to classify Wikipedia comments as toxic/nontoxic. The data has been sourced from Google and Jigsaw. \n",
    "\n",
    "Though the full dataset includes non-English comments, I will restrict myself to English-only comment for this iteration. \n",
    "\n",
    "I will explore deep learning approaches, using a combination of pretrained word embeddings and simple deep learning models like RNNs and 1D convolutions to do more benchmarking. \n",
    "\n",
    "Next, we will explore deep learning models that have 'memory' using LSTMs (Long Short Term Memory) and GRUs (Gated Recurrent Units). \n",
    "\n",
    "Finally, we will approach state of the art performance using pretrained models like BERT and xlnet.\n",
    "\n",
    "For metrics, I will focus on both ROC and precision-recall curves. In addition, I will look at the confusion matrix and performance across different flavors of toxicity.\n",
    "\n",
    "Credits:\n",
    "- https://www.kaggle.com/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert\n",
    "- https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda\n",
    "- https://www.kaggle.com/clinma/eda-toxic-comment-classification-challenge\n",
    "- https://www.kaggle.com/abhi111/naive-bayes-baseline-and-logistic-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6hORXZtChfmh"
   },
   "source": [
    "My approach to feature engineering and building the model is below:\n",
    "\n",
    "Deep Learning:\n",
    "1. Use standard tokenizers and compare with 'homegrown' version from above.\n",
    "2. Use open source word embeddings for corpus as input to RNN models. Quantify how misspellings affect the standard tokenizers.\n",
    "3. Find way to input additional features like punctuation/capitalization from approach above to Deep Learning RNN models.\n",
    "4. Try progressively more complicated deep learning sequence models approaching SOTA.\n",
    "5. Use metrics from above.\n",
    "\n",
    "Potential Modules:\n",
    "1. Correct misspellings\n",
    "2. Analytics for preprocessing\n",
    "3. Analytics for model performance (use multi-labels, make easy way to look at specific examples)\n",
    "4. Automatically generate a lookup table for common variations of words (particularly toxic words, e.g., 'mothafucka' -> 'motherfucker')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q8G3RM3rn4eZ"
   },
   "source": [
    "## Install requirements as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U_wYN97Qhfmh"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "  \n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "#Uncomment below if running in colab\n",
    "#!pip install tokenizers\n",
    "#!pip install transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Riw_wcwYnjWA"
   },
   "source": [
    "# Install toxicity package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "nfmoOvnchfmr",
    "outputId": "1c00e8b1-6706-44c4-823a-078dfe404912"
   },
   "outputs": [],
   "source": [
    "#Run below if toxicity package is not installed\n",
    "#!pip install --upgrade git+https://github.com/jkchandalia/toxic-comment-classifier.git@fe5dfe51f09322c166cce0a56818f66a2a2fc5c7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815,
     "referenced_widgets": [
      "bc8a03b077ab4fc29fea6620c3b8ec6d",
      "3aa58e9a6ed545918c2eee459eb731cb",
      "f652ba899a05429a8f5d2fd8b3528a0d",
      "e421f8128bbd4eec903a8fba84bf684d",
      "109e473e588149a7bf97d483a5f0520e",
      "e88ba82b92b7420ab45d28fac47e60ed",
      "b47f3ec2b075450ba0240b1cafc5c3d6",
      "96c07cefad0f4fdbbcd2e5611f6bc836",
      "c5de80398b93435ca8cb59c2e741aae2",
      "385342fbe947406ba8da777e7e887de0",
      "0c3691dbb85a44969ace25fbbe5f20a6",
      "622580b7962f45a9845ce4f6728dfe66",
      "4ef71166a53f4c9aba0eced4441568e1",
      "6ae7cc699f854109b10016ee762d0712",
      "a6b2861a7ae9481093c0df5a6f0e4f8a",
      "56d6a79b83a84d5cbc5c3d996dce4168"
     ]
    },
    "colab_type": "code",
    "id": "17upe_Jwhfmu",
    "outputId": "f2ea0f53-04b4-4fd5-ba03-d99e84b7b7b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing TFDistilBertModel: ['vocab_projector', 'vocab_transform', 'vocab_layer_norm', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-cased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from toxicity import constants, data, features, metrics, visualize, model, text_preprocessing, model_BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OITDhWOBhfmw"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "p5AbRd0BiKd4",
    "outputId": "403ce278-ee10-4ac4-bbb3-e0f810f57c40"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#Mount drive if using google colab nb\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "LPMEZItIhfmx",
    "outputId": "aceeae41-c7b6-4c19-f3ca-708ef88d5511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Toxic Comments: \n",
      "['Hey... what is it..\\n@ | talk .\\nWhat is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\\n\\nAsk Sityush to clean up his behavior than issue me nonsensical warnings...']\n",
      "Breakdown of nontoxic/toxic comments: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    202165\n",
       "1     21384\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use below for local\n",
    "pre_path = './'\n",
    "#Use below for paperspace\n",
    "#pre_path = '/storage/'\n",
    "#Use below for colab with drive mounted\n",
    "#pre_path = '/content/drive/My Drive/toximeter_project/'\n",
    "input_data_path = pre_path+constants.INPUT_PATH\n",
    "df_train = data.load(input_data_path, filter=False)\n",
    "\n",
    "train_full = df_train.copy()\n",
    "#df_train = df_train.loc[:10000,:]\n",
    "print(\"Sample Toxic Comments: \")\n",
    "print(df_train.comment_text[df_train.toxic==1][1:2].values)\n",
    "print(\"Breakdown of nontoxic/toxic comments: \")\n",
    "df_train.toxic.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "38-z-Stihfmz"
   },
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = model.make_train_test(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ox7Sj_Aehfm1",
    "outputId": "02c6590e-0bf4-4805-847c-23fe6f4aefb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44710"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W4FLco_fhfm4"
   },
   "source": [
    "## Use Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S0FqKzkxhfm7"
   },
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hxGrRVVshfm7"
   },
   "source": [
    "### We will check the maximum number of words that can be present in a comment , this will help us in padding later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HemRUBD3hfm7",
    "outputId": "a956c28f-835e-4f1e-94d8-8a7c1f853178"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of comment text is: 2400\n"
     ]
    }
   ],
   "source": [
    "max_len = model_BERT.find_max_len(df_train['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tROk0j-5hfm-"
   },
   "source": [
    "### First do Tokenization of input corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XQ1gWUFfhfm-"
   },
   "outputs": [],
   "source": [
    "# using keras tokenizer here\n",
    "token = text.Tokenizer(num_words=None)\n",
    "token_toxic = text.Tokenizer(num_words=None)\n",
    "token_nontoxic = text.Tokenizer(num_words=None)\n",
    "\n",
    "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
    "token_toxic.fit_on_texts(df_train.comment_text.values[df_train.toxic==1])\n",
    "token_nontoxic.fit_on_texts(df_train.comment_text.values[df_train.toxic==0])\n",
    "\n",
    "xtrain_seq = token.texts_to_sequences(xtrain)\n",
    "xvalid_seq = token.texts_to_sequences(xvalid)\n",
    "\n",
    "#zero pad the sequences\n",
    "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21sIaqR_hfnA"
   },
   "outputs": [],
   "source": [
    "word_toxic = token_toxic.word_index\n",
    "word_nontoxic = token_nontoxic.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IdB-9G4hhfnC",
    "outputId": "4343d46b-dbe2-42c8-b996-bac5f2f14fa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42681\n",
      "288956\n"
     ]
    }
   ],
   "source": [
    "print(len(word_toxic))\n",
    "print(len(word_nontoxic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GshhoGCBhfnE"
   },
   "source": [
    "Example for fitting tokenizer line-by-line if corpus is too big to fit into memory\n",
    "\n",
    "with open('/Users/liling.tan/test.txt') as fin: for line in fin:\n",
    "t.fit_on_texts(line.split()) # Fitting the tokenizer line-by-line.\n",
    "\n",
    "M = []\n",
    "\n",
    "with open('/Users/liling.tan/test.txt') as fin: for line in fin:\n",
    "\n",
    "    # Converting the lines into matrix, line-by-line.\n",
    "    m = t.texts_to_matrix([line], mode='count')[0]\n",
    "    M.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GttFyDuOhfnF"
   },
   "source": [
    "## Use pretrained word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VhNQm3UdhfnF"
   },
   "source": [
    "## Convert our one-hot word index into semantic rich GloVe vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-U4p6ZrWhfnG"
   },
   "outputs": [],
   "source": [
    "# load the GloVe vectors in a dictionary:\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(pre_path + 'glove840b300dtxt/glove.840B.300d.txt','r',encoding='utf-8')\n",
    "for line in tqdm(f):\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray([float(val) for val in values[1:]])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JcG9og4dhfnI"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "words_not_in_corpus = ddict(int)\n",
    "words_in_corpus = ddict(int)\n",
    "# create an embedding matrix for the words we have in the dataset\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_nontoxic.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        words_in_corpus[word]+=1\n",
    "    else:\n",
    "        words_not_in_corpus[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAJkvkcahfnK"
   },
   "outputs": [],
   "source": [
    "print(len(words_not_in_corpus))\n",
    "print(len(words_in_corpus))\n",
    "max(words_not_in_corpus.values())\n",
    "max(words_in_corpus.values())\n",
    "\n",
    "#For the full dataset, more than half the 'words' are not found in the glove embeddings\n",
    "#For the 10K sample dataset, only ~25% of the words are not found in the glove embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_eh0wi0QhfnL"
   },
   "outputs": [],
   "source": [
    "print(len(words_not_in_corpus))\n",
    "print(len(words_in_corpus))\n",
    "max(words_not_in_corpus.values())\n",
    "max(words_in_corpus.values())\n",
    "\n",
    "#For the full dataset, more than half the 'words' are not found in the glove embeddings\n",
    "#For the 10K sample dataset, only ~25% of the words are not found in the glove embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0XAPk0YhfnO"
   },
   "outputs": [],
   "source": [
    "#Save embeddings so they can be easily loaded\n",
    "np.save('/kaggle/working/glove_embedding_for_full_data', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J8itT1yshfnQ",
    "outputId": "543f5ca0-fbec-4064-932f-6451b644bfa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jkc/workspace/toxic-comment-classifier/exploration/DL_experiments'"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.abspath('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDGwQI2phfnS"
   },
   "outputs": [],
   "source": [
    "#Load embeddings\n",
    "embedding_matrix = np.load(pre_path+'data/embedding_for_lstm_all.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sJUkafE-hfnU",
    "outputId": "d9336c18-2cce-4d87-8703-4207115c06fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300258, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2VNIq9VfhfnW"
   },
   "source": [
    "## Simple RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CCieHGhhhfnW"
   },
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uFFt9ftqhfnY"
   },
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(len(word_index) + 1,\n",
    "                 300,\n",
    "                 input_length=max_len))\n",
    "model1.add(SimpleRNN(100))\n",
    "model1.add(Dense(1, activation='relu'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zO0wlU75hfna",
    "outputId": "73f5c344-ec7d-41c2-895e-9fd70474bfe7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.ModelCheckpoint at 0x21f435ad0>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "EPOCHS = 10\n",
    "checkpoint_filepath = './checkpoint'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "my_callbacks = [\n",
    "    model_checkpoint_callback,\n",
    "    TensorBoard(log_dir='./logs'),\n",
    "    EarlyStopping(monitor='val_loss', patience=3)\n",
    "]\n",
    "model_checkpoint_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LVkpfx80hfnd"
   },
   "outputs": [],
   "source": [
    "model1.fit(xtrain_pad, \n",
    "           ytrain, \n",
    "           epochs=50, \n",
    "           batch_size=100, \n",
    "           callbacks=my_callbacks,\n",
    "           validation_split=0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wKSTGIP2hfnf"
   },
   "outputs": [],
   "source": [
    "scores = model1.predict(xvalid_pad)[:, 0]\n",
    "preds = scores>.5\n",
    "run_metrics(preds, scores, yvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1PbLJaYohfnh"
   },
   "source": [
    "## Simple LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "jq6xgRL1hfnj",
    "outputId": "a97677c7-4fd3-4f64-b7e4-079a83ad4aa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 2400, 300)         90077400  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 90,237,901\n",
      "Trainable params: 160,501\n",
      "Non-trainable params: 90,077,400\n",
      "_________________________________________________________________\n",
      "CPU times: user 1.99 s, sys: 550 ms, total: 2.54 s\n",
      "Wall time: 5.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# A simple LSTM with glove embeddings and one dense layer\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                 300,\n",
    "                 weights=[embedding_matrix],\n",
    "                 input_length=max_len,\n",
    "                 trainable=False))\n",
    "\n",
    "model.add(LSTM(100, activation=\"tanh\",\n",
    "    recurrent_activation=\"sigmoid\", dropout=0.2, recurrent_dropout=0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy', AUC(curve='PR')])\n",
    "    \n",
    "model.summary()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ok2tjPPio4_6",
    "outputId": "0405e580-58c5-4047-a887-ee89d605d2aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a callback for tensorboard\n",
    "tb_callback = TensorBoard(log_dir=pre_path+'glove_lstm_frozen_10Ksample/Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "# Create a callback that saves the model's weights every epoch\n",
    "checkpoint_path = pre_path+\"training/glove_lstm_frozen_10Ksample/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch',\n",
    "    period=5)\n",
    "\n",
    "# Callback for early stopping if model isn't improving\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "76RYMq3Lhfnl",
    "outputId": "0dc53247-6aa6-4403-ac04-b5371566497e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      " 1/64 [..............................] - ETA: 1s - loss: 0.7763 - accuracy: 0.1800 - auc: 0.0728WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/64 [..............................] - ETA: 17s - loss: 0.6973 - accuracy: 0.5050 - auc: 0.0666WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1573s vs `on_train_batch_end` time: 0.3763s). Check your callbacks.\n",
      "64/64 [==============================] - 12s 180ms/step - loss: 0.2646 - accuracy: 0.9058 - auc: 0.3848 - val_loss: 0.1525 - val_accuracy: 0.9413 - val_auc: 0.8135\n",
      "Epoch 2/120\n",
      "64/64 [==============================] - 11s 164ms/step - loss: 0.1545 - accuracy: 0.9447 - auc: 0.7495 - val_loss: 0.1368 - val_accuracy: 0.9500 - val_auc: 0.8402\n",
      "Epoch 3/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.1334 - accuracy: 0.9530 - auc: 0.7975 - val_loss: 0.1205 - val_accuracy: 0.9600 - val_auc: 0.8667\n",
      "Epoch 4/120\n",
      "64/64 [==============================] - 10s 164ms/step - loss: 0.1177 - accuracy: 0.9597 - auc: 0.8394 - val_loss: 0.1232 - val_accuracy: 0.9569 - val_auc: 0.8760\n",
      "Epoch 5/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9623 - auc: 0.8645\n",
      "Epoch 00005: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0005.ckpt\n",
      "64/64 [==============================] - 11s 174ms/step - loss: 0.1074 - accuracy: 0.9623 - auc: 0.8645 - val_loss: 0.1101 - val_accuracy: 0.9619 - val_auc: 0.8756\n",
      "Epoch 6/120\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 0.0968 - accuracy: 0.9652 - auc: 0.8896 - val_loss: 0.1130 - val_accuracy: 0.9625 - val_auc: 0.8717\n",
      "Epoch 7/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.0888 - accuracy: 0.9678 - auc: 0.9016 - val_loss: 0.1371 - val_accuracy: 0.9556 - val_auc: 0.8502\n",
      "Epoch 8/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0798 - accuracy: 0.9703 - auc: 0.9218 - val_loss: 0.1229 - val_accuracy: 0.9544 - val_auc: 0.8732\n",
      "Epoch 9/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0717 - accuracy: 0.9737 - auc: 0.9376 - val_loss: 0.1358 - val_accuracy: 0.9556 - val_auc: 0.8424\n",
      "Epoch 10/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9770 - auc: 0.9477\n",
      "Epoch 00010: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0010.ckpt\n",
      "64/64 [==============================] - 11s 170ms/step - loss: 0.0629 - accuracy: 0.9770 - auc: 0.9477 - val_loss: 0.1273 - val_accuracy: 0.9525 - val_auc: 0.8494\n",
      "Epoch 11/120\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 0.0473 - accuracy: 0.9828 - auc: 0.9710 - val_loss: 0.1321 - val_accuracy: 0.9463 - val_auc: 0.8547\n",
      "Epoch 12/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0411 - accuracy: 0.9847 - auc: 0.9791 - val_loss: 0.1617 - val_accuracy: 0.9475 - val_auc: 0.8289\n",
      "Epoch 13/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0254 - accuracy: 0.9916 - auc: 0.9918 - val_loss: 0.1595 - val_accuracy: 0.9594 - val_auc: 0.8352\n",
      "Epoch 14/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0168 - accuracy: 0.9948 - auc: 0.9977 - val_loss: 0.1697 - val_accuracy: 0.9475 - val_auc: 0.8189\n",
      "Epoch 15/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9961 - auc: 0.9966\n",
      "Epoch 00015: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0015.ckpt\n",
      "64/64 [==============================] - 11s 170ms/step - loss: 0.0163 - accuracy: 0.9961 - auc: 0.9966 - val_loss: 0.1696 - val_accuracy: 0.9506 - val_auc: 0.8294\n",
      "Epoch 16/120\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 0.0092 - accuracy: 0.9980 - auc: 0.9997 - val_loss: 0.1953 - val_accuracy: 0.9538 - val_auc: 0.8104\n",
      "Epoch 17/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0045 - accuracy: 0.9995 - auc: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9525 - val_auc: 0.8076\n",
      "Epoch 18/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0028 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9519 - val_auc: 0.8001\n",
      "Epoch 19/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0019 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9513 - val_auc: 0.7976\n",
      "Epoch 20/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 00020: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0020.ckpt\n",
      "64/64 [==============================] - 11s 169ms/step - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9506 - val_auc: 0.7791\n",
      "Epoch 21/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9531 - val_auc: 0.7739\n",
      "Epoch 22/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 8.1014e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2777 - val_accuracy: 0.9494 - val_auc: 0.7629\n",
      "Epoch 23/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 6.3153e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9469 - val_auc: 0.7654\n",
      "Epoch 24/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 5.4329e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.9494 - val_auc: 0.7587\n",
      "Epoch 25/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 4.4041e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 00025: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0025.ckpt\n",
      "64/64 [==============================] - 11s 169ms/step - loss: 4.4041e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9475 - val_auc: 0.7582\n",
      "Epoch 26/120\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 3.6886e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.9494 - val_auc: 0.7453\n",
      "Epoch 27/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 3.1448e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3122 - val_accuracy: 0.9488 - val_auc: 0.7492\n",
      "Epoch 28/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 2.7136e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3134 - val_accuracy: 0.9488 - val_auc: 0.7460\n",
      "Epoch 29/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 2.3527e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3243 - val_accuracy: 0.9488 - val_auc: 0.7488\n",
      "Epoch 30/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.0662e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 00030: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0030.ckpt\n",
      "64/64 [==============================] - 11s 169ms/step - loss: 2.0662e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9469 - val_auc: 0.7510\n",
      "Epoch 31/120\n",
      "64/64 [==============================] - 11s 168ms/step - loss: 1.8297e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3311 - val_accuracy: 0.9488 - val_auc: 0.7415\n",
      "Epoch 32/120\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 1.6507e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9494 - val_auc: 0.7430\n",
      "Epoch 33/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 1.4864e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.9488 - val_auc: 0.7392\n",
      "Epoch 34/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 1.4020e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9475 - val_auc: 0.7391\n",
      "Epoch 35/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.2658e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 00035: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0035.ckpt\n",
      "64/64 [==============================] - 11s 170ms/step - loss: 1.2658e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9481 - val_auc: 0.7345\n",
      "Epoch 36/120\n",
      "64/64 [==============================] - 11s 168ms/step - loss: 1.0989e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3477 - val_accuracy: 0.9469 - val_auc: 0.7401\n",
      "Epoch 37/120\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 1.0172e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.9494 - val_auc: 0.7407\n",
      "Epoch 38/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 9.3330e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.9469 - val_auc: 0.7405\n",
      "Epoch 39/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 8.5560e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.9463 - val_auc: 0.7302\n",
      "Epoch 40/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 7.8294e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 00040: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0040.ckpt\n",
      "64/64 [==============================] - 11s 172ms/step - loss: 7.8294e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3659 - val_accuracy: 0.9469 - val_auc: 0.7350\n",
      "Epoch 41/120\n",
      "64/64 [==============================] - 11s 168ms/step - loss: 7.4593e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3670 - val_accuracy: 0.9469 - val_auc: 0.7274\n",
      "Epoch 42/120\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 6.9278e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3712 - val_accuracy: 0.9475 - val_auc: 0.7321\n",
      "Epoch 43/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 6.4335e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9475 - val_auc: 0.7244\n",
      "Epoch 44/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 5.7250e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.9481 - val_auc: 0.7246\n",
      "Epoch 45/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 5.3859e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 00045: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0045.ckpt\n",
      "64/64 [==============================] - 11s 169ms/step - loss: 5.3859e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9469 - val_auc: 0.7209\n",
      "Epoch 46/120\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 4.9116e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.9475 - val_auc: 0.7225\n",
      "Epoch 47/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 4.6234e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9475 - val_auc: 0.7248\n",
      "Epoch 48/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 4.3759e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.9469 - val_auc: 0.7194\n",
      "Epoch 49/120\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 4.0529e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.9469 - val_auc: 0.7219\n",
      "Epoch 50/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.8774e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 00050: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0050.ckpt\n",
      "64/64 [==============================] - 11s 169ms/step - loss: 3.8774e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3985 - val_accuracy: 0.9475 - val_auc: 0.7222\n",
      "Epoch 51/120\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 3.5851e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.9450 - val_auc: 0.7114\n",
      "Epoch 52/120\n",
      "64/64 [==============================] - 11s 164ms/step - loss: 3.3480e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.9456 - val_auc: 0.7044\n",
      "Epoch 53/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 3.1086e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.9463 - val_auc: 0.7160\n",
      "Epoch 54/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 2.9685e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.9456 - val_auc: 0.7049\n",
      "Epoch 55/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.9267e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 00055: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0055.ckpt\n",
      "64/64 [==============================] - 11s 170ms/step - loss: 2.9267e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.9481 - val_auc: 0.7115\n",
      "Epoch 56/120\n",
      "64/64 [==============================] - 11s 168ms/step - loss: 2.6909e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.9475 - val_auc: 0.7115\n",
      "Epoch 57/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 2.5083e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.9444 - val_auc: 0.6952\n",
      "Epoch 58/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 2.3486e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4218 - val_accuracy: 0.9450 - val_auc: 0.7005\n",
      "Epoch 59/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 2.2369e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.9463 - val_auc: 0.7111\n",
      "Epoch 60/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.1229e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 00060: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0060.ckpt\n",
      "64/64 [==============================] - 11s 170ms/step - loss: 2.1229e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.9450 - val_auc: 0.6962\n",
      "Epoch 61/120\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 2.0421e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.9456 - val_auc: 0.7006\n",
      "Epoch 62/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 1.9149e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.9450 - val_auc: 0.6996\n",
      "Epoch 63/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.1457 - accuracy: 0.9783 - auc: 0.8808 - val_loss: 0.9528 - val_accuracy: 0.9106 - val_auc: 0.3493\n",
      "Epoch 64/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.2306 - accuracy: 0.9420 - auc: 0.6804 - val_loss: 0.1418 - val_accuracy: 0.9444 - val_auc: 0.8113\n",
      "Epoch 65/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.9595 - auc: 0.8524\n",
      "Epoch 00065: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0065.ckpt\n",
      "64/64 [==============================] - 11s 169ms/step - loss: 0.1154 - accuracy: 0.9595 - auc: 0.8524 - val_loss: 0.1239 - val_accuracy: 0.9519 - val_auc: 0.8464\n",
      "Epoch 66/120\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 0.0914 - accuracy: 0.9692 - auc: 0.9042 - val_loss: 0.1232 - val_accuracy: 0.9506 - val_auc: 0.8517\n",
      "Epoch 67/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.0764 - accuracy: 0.9745 - auc: 0.9309 - val_loss: 0.1163 - val_accuracy: 0.9563 - val_auc: 0.8599\n",
      "Epoch 68/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.0624 - accuracy: 0.9791 - auc: 0.9528 - val_loss: 0.1162 - val_accuracy: 0.9606 - val_auc: 0.8698\n",
      "Epoch 69/120\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 0.0516 - accuracy: 0.9822 - auc: 0.9669 - val_loss: 0.1136 - val_accuracy: 0.9619 - val_auc: 0.8701\n",
      "Epoch 70/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9869 - auc: 0.9766\n",
      "Epoch 00070: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0070.ckpt\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 0.0432 - accuracy: 0.9869 - auc: 0.9766 - val_loss: 0.1162 - val_accuracy: 0.9563 - val_auc: 0.8676\n",
      "Epoch 71/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.0361 - accuracy: 0.9905 - auc: 0.9819 - val_loss: 0.1168 - val_accuracy: 0.9588 - val_auc: 0.8694\n",
      "Epoch 72/120\n",
      "64/64 [==============================] - 11s 164ms/step - loss: 0.0305 - accuracy: 0.9931 - auc: 0.9861 - val_loss: 0.1211 - val_accuracy: 0.9575 - val_auc: 0.8689\n",
      "Epoch 73/120\n",
      "64/64 [==============================] - 11s 164ms/step - loss: 0.0251 - accuracy: 0.9948 - auc: 0.9898 - val_loss: 0.1275 - val_accuracy: 0.9613 - val_auc: 0.8671\n",
      "Epoch 74/120\n",
      "64/64 [==============================] - 11s 164ms/step - loss: 0.0218 - accuracy: 0.9955 - auc: 0.9919 - val_loss: 0.1225 - val_accuracy: 0.9588 - val_auc: 0.8711\n",
      "Epoch 75/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9967 - auc: 0.9935\n",
      "Epoch 00075: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0075.ckpt\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0183 - accuracy: 0.9967 - auc: 0.9935 - val_loss: 0.1337 - val_accuracy: 0.9600 - val_auc: 0.8675\n",
      "Epoch 76/120\n",
      "64/64 [==============================] - 10s 164ms/step - loss: 0.0167 - accuracy: 0.9975 - auc: 0.9932 - val_loss: 0.1344 - val_accuracy: 0.9619 - val_auc: 0.8653\n",
      "Epoch 77/120\n",
      "64/64 [==============================] - 10s 162ms/step - loss: 0.0140 - accuracy: 0.9977 - auc: 0.9952 - val_loss: 0.1444 - val_accuracy: 0.9613 - val_auc: 0.8594\n",
      "Epoch 78/120\n",
      "64/64 [==============================] - 10s 162ms/step - loss: 0.0121 - accuracy: 0.9983 - auc: 0.9958 - val_loss: 0.1440 - val_accuracy: 0.9594 - val_auc: 0.8642\n",
      "Epoch 79/120\n",
      "64/64 [==============================] - 10s 163ms/step - loss: 0.0117 - accuracy: 0.9980 - auc: 0.9959 - val_loss: 0.1518 - val_accuracy: 0.9519 - val_auc: 0.8371\n",
      "Epoch 80/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9983 - auc: 0.9961\n",
      "Epoch 00080: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0080.ckpt\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.0117 - accuracy: 0.9983 - auc: 0.9961 - val_loss: 0.1464 - val_accuracy: 0.9600 - val_auc: 0.8636\n",
      "Epoch 81/120\n",
      "64/64 [==============================] - 10s 164ms/step - loss: 0.0250 - accuracy: 0.9936 - auc: 0.9875 - val_loss: 0.1363 - val_accuracy: 0.9588 - val_auc: 0.8750\n",
      "Epoch 82/120\n",
      "64/64 [==============================] - 10s 162ms/step - loss: 0.0120 - accuracy: 0.9981 - auc: 0.9963 - val_loss: 0.1419 - val_accuracy: 0.9575 - val_auc: 0.8677\n",
      "Epoch 83/120\n",
      "64/64 [==============================] - 10s 161ms/step - loss: 0.0092 - accuracy: 0.9991 - auc: 0.9968 - val_loss: 0.1493 - val_accuracy: 0.9594 - val_auc: 0.8662\n",
      "Epoch 84/120\n",
      "64/64 [==============================] - 10s 163ms/step - loss: 0.0076 - accuracy: 0.9991 - auc: 0.9970 - val_loss: 0.1514 - val_accuracy: 0.9594 - val_auc: 0.8584\n",
      "Epoch 85/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9992 - auc: 0.9972\n",
      "Epoch 00085: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0085.ckpt\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 0.0067 - accuracy: 0.9992 - auc: 0.9972 - val_loss: 0.1559 - val_accuracy: 0.9581 - val_auc: 0.8581\n",
      "Epoch 86/120\n",
      "64/64 [==============================] - 10s 163ms/step - loss: 0.0061 - accuracy: 0.9992 - auc: 0.9987 - val_loss: 0.1605 - val_accuracy: 0.9600 - val_auc: 0.8529\n",
      "Epoch 87/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.0054 - accuracy: 0.9992 - auc: 0.9989 - val_loss: 0.1664 - val_accuracy: 0.9606 - val_auc: 0.8427\n",
      "Epoch 88/120\n",
      "64/64 [==============================] - 10s 162ms/step - loss: 0.0048 - accuracy: 0.9994 - auc: 0.9990 - val_loss: 0.1835 - val_accuracy: 0.9581 - val_auc: 0.8321\n",
      "Epoch 89/120\n",
      "64/64 [==============================] - 10s 164ms/step - loss: 0.0052 - accuracy: 0.9992 - auc: 0.9991 - val_loss: 0.1667 - val_accuracy: 0.9600 - val_auc: 0.8499\n",
      "Epoch 90/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9995 - auc: 0.9992\n",
      "Epoch 00090: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0090.ckpt\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0042 - accuracy: 0.9995 - auc: 0.9992 - val_loss: 0.1721 - val_accuracy: 0.9600 - val_auc: 0.8370\n",
      "Epoch 91/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0037 - accuracy: 0.9995 - auc: 0.9995 - val_loss: 0.1764 - val_accuracy: 0.9594 - val_auc: 0.8250\n",
      "Epoch 92/120\n",
      "64/64 [==============================] - 10s 162ms/step - loss: 0.0034 - accuracy: 0.9995 - auc: 0.9996 - val_loss: 0.1803 - val_accuracy: 0.9600 - val_auc: 0.8224\n",
      "Epoch 93/120\n",
      "64/64 [==============================] - 10s 164ms/step - loss: 0.0031 - accuracy: 0.9995 - auc: 0.9997 - val_loss: 0.1836 - val_accuracy: 0.9606 - val_auc: 0.8174\n",
      "Epoch 94/120\n",
      "64/64 [==============================] - 10s 163ms/step - loss: 0.0029 - accuracy: 0.9997 - auc: 0.9998 - val_loss: 0.1938 - val_accuracy: 0.9613 - val_auc: 0.8118\n",
      "Epoch 95/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9997 - auc: 0.9999\n",
      "Epoch 00095: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0095.ckpt\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0027 - accuracy: 0.9997 - auc: 0.9999 - val_loss: 0.1928 - val_accuracy: 0.9613 - val_auc: 0.8121\n",
      "Epoch 96/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.0024 - accuracy: 0.9997 - auc: 0.9999 - val_loss: 0.1946 - val_accuracy: 0.9600 - val_auc: 0.8120\n",
      "Epoch 97/120\n",
      "64/64 [==============================] - 10s 163ms/step - loss: 0.0022 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9600 - val_auc: 0.8121\n",
      "Epoch 98/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.0020 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9594 - val_auc: 0.8126\n",
      "Epoch 99/120\n",
      "64/64 [==============================] - 10s 163ms/step - loss: 0.0019 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9600 - val_auc: 0.8081\n",
      "Epoch 100/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9987 - auc: 0.9975\n",
      "Epoch 00100: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0100.ckpt\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0051 - accuracy: 0.9987 - auc: 0.9975 - val_loss: 0.2452 - val_accuracy: 0.9425 - val_auc: 0.7725\n",
      "Epoch 101/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0164 - accuracy: 0.9942 - auc: 0.9952 - val_loss: 0.1623 - val_accuracy: 0.9556 - val_auc: 0.8531\n",
      "Epoch 102/120\n",
      "64/64 [==============================] - 10s 164ms/step - loss: 0.0040 - accuracy: 0.9995 - auc: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9619 - val_auc: 0.8513\n",
      "Epoch 103/120\n",
      "64/64 [==============================] - 10s 164ms/step - loss: 0.0024 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9600 - val_auc: 0.8482\n",
      "Epoch 104/120\n",
      "64/64 [==============================] - 10s 164ms/step - loss: 0.0020 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9613 - val_auc: 0.8394\n",
      "Epoch 105/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9997 - auc: 1.0000\n",
      "Epoch 00105: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0105.ckpt\n",
      "64/64 [==============================] - 11s 168ms/step - loss: 0.0017 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9606 - val_auc: 0.8394\n",
      "Epoch 106/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0015 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9600 - val_auc: 0.8400\n",
      "Epoch 107/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.0013 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9594 - val_auc: 0.8382\n",
      "Epoch 108/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.0012 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9594 - val_auc: 0.8377\n",
      "Epoch 109/120\n",
      "64/64 [==============================] - 10s 164ms/step - loss: 0.0011 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9600 - val_auc: 0.8357\n",
      "Epoch 110/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 9.5866e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 00110: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0110.ckpt\n",
      "64/64 [==============================] - 11s 168ms/step - loss: 9.5866e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9594 - val_auc: 0.8295\n",
      "Epoch 111/120\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 8.5546e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9594 - val_auc: 0.8300\n",
      "Epoch 112/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 7.8414e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9613 - val_auc: 0.8228\n",
      "Epoch 113/120\n",
      "64/64 [==============================] - 10s 164ms/step - loss: 7.1260e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9619 - val_auc: 0.8233\n",
      "Epoch 114/120\n",
      "64/64 [==============================] - 11s 164ms/step - loss: 6.5708e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9619 - val_auc: 0.8188\n",
      "Epoch 115/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 6.0636e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 00115: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0115.ckpt\n",
      "64/64 [==============================] - 11s 169ms/step - loss: 6.0636e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9619 - val_auc: 0.8189\n",
      "Epoch 116/120\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 5.6323e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9613 - val_auc: 0.8081\n",
      "Epoch 117/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 5.2358e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9613 - val_auc: 0.8087\n",
      "Epoch 118/120\n",
      "64/64 [==============================] - 10s 163ms/step - loss: 4.8692e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9613 - val_auc: 0.8068\n",
      "Epoch 119/120\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 4.5260e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9613 - val_auc: 0.8070\n",
      "Epoch 120/120\n",
      "64/64 [==============================] - ETA: 0s - loss: 4.2971e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 00120: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_frozen_10Ksample/cp-0120.ckpt\n",
      "64/64 [==============================] - 11s 169ms/step - loss: 4.2971e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9613 - val_auc: 0.8073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f10accc16d8>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_pad, \n",
    "          ytrain, \n",
    "          epochs=120, \n",
    "          batch_size=100,\n",
    "          callbacks=[tb_callback, cp_callback],\n",
    "          validation_split=0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u81FWBhrhfnn"
   },
   "outputs": [],
   "source": [
    "scores = model.predict(xvalid_pad)\n",
    "preds = scores>.5\n",
    "run_metrics(preds, scores, yvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1_rHL3Gghfnp"
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u8meW9PKhfnp"
   },
   "source": [
    "So far, with very little preprocessing, we have achieved high accuracy. This is a little bit misleading however because the training set is highly imbalanced (roughly 10% positive/toxic class). \n",
    "\n",
    "Slightly older techniques, bag-of-words and tf-idf have done better than a simple deep learning models out-of-the-box. This can been seen by the higher AUCs and accuracy of these models in contrast to the simple RNN model. In addition, training these models was extremely fast, even on a local machine. In contrast, the deep learning models required more than 10 minutes to train even five epochs. In addition, trainingg the simple RNN required playing around with the learning rate to get network to learn. The first few attempts produced labels of all zeros. \n",
    "\n",
    "The simple LSTM model starts to improve dramatically over the simple RNN model even with only 5 epochs, showing that using the semantic rich word embeddings and including memory already improve simple deep learning results. Though the overall accuracy has decreased in the LSTM model vs the Naive Bayes models, the AUC and precision-recall and ROC curves are much better than the simple models. As we approach more state-of-the-art (SOTA) models and move beyond simple proof-of-concept model training, i.e., try different network parameters, experiment with data preprocessing, do hyperparameter optimization, train until the results start to degrade, add regularization, etc., the results will likely improve even more dramatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sR83aZWlhfnp"
   },
   "source": [
    "## Try a GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R8G7JUQPhfnq"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# GRU with glove embeddings and two dense layers\n",
    " model = Sequential()\n",
    " model.add(Embedding(len(word_index) + 1,\n",
    "                 300,\n",
    "                 weights=[embedding_matrix],\n",
    "                 input_length=max_len,\n",
    "                 trainable=False))\n",
    " model.add(SpatialDropout1D(0.3))\n",
    " model.add(GRU(300))\n",
    " model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    " model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])   \n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6i8Pd11hfnr"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# GRU with glove embeddings and two dense layers\n",
    " model = Sequential()\n",
    " model.add(Embedding(len(word_index) + 1,\n",
    "                 300,\n",
    "                 weights=[embedding_matrix],\n",
    "                 input_length=max_len,\n",
    "                 trainable=False))\n",
    " model.add(SpatialDropout1D(0.3))\n",
    " model.add(GRU(300))\n",
    " model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    " model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])   \n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kC35nGr0hfnt"
   },
   "outputs": [],
   "source": [
    "model.fit(xtrain_pad, ytrain, nb_epoch=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EZAYVisvhfnv"
   },
   "outputs": [],
   "source": [
    "scores = model.predict(xvalid_pad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tnt5p4qehfnw"
   },
   "source": [
    "## Bidirectional RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ujd-IIfhfnx"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# A simple bidirectional LSTM with glove embeddings and one dense layer\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                 300,\n",
    "                 weights=[embedding_matrix],\n",
    "                 input_length=max_len,\n",
    "                 trainable=False))\n",
    "model.add(Bidirectional(LSTM(300, dropout=0.3, recurrent_dropout=0.3)))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2RWzYTbhfnz"
   },
   "outputs": [],
   "source": [
    "model.fit(xtrain_pad, ytrain, nb_epoch=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-6WKROURhfn0"
   },
   "outputs": [],
   "source": [
    "scores = model.predict(xvalid_pad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cJT6fPUihfn2"
   },
   "source": [
    "## Seq2seq Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6jV8rm4hfn3"
   },
   "outputs": [],
   "source": [
    "#TBD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "a4NhHSrLCZ1c"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU,SimpleRNN\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping, History, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.metrics import Accuracy, AUC\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wg-6adeuCZ1o"
   },
   "outputs": [],
   "source": [
    "# using keras tokenizer here\n",
    "token = text.Tokenizer(num_words=None)\n",
    "token_toxic = text.Tokenizer(num_words=None)\n",
    "token_nontoxic = text.Tokenizer(num_words=None)\n",
    "\n",
    "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
    "token_toxic.fit_on_texts(df_train.comment_text.values[df_train.toxic==1])\n",
    "token_nontoxic.fit_on_texts(df_train.comment_text.values[df_train.toxic==0])\n",
    "\n",
    "xtrain_seq = token.texts_to_sequences(xtrain)\n",
    "xvalid_seq = token.texts_to_sequences(xvalid)\n",
    "\n",
    "#zero pad the sequences\n",
    "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ROuURkSnCZ1q"
   },
   "outputs": [],
   "source": [
    "#Load embeddings\n",
    "embedding_matrix = np.load(pre_path+'data/embedding_for_lstm_all.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "remBu2yyCZ1t"
   },
   "source": [
    "## Simple LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "FHj4SYYLCZ1u",
    "outputId": "5c0f5529-3ddd-4050-afbd-1e4e06072673"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2400, 300)         90077400  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 90,237,901\n",
      "Trainable params: 160,501\n",
      "Non-trainable params: 90,077,400\n",
      "_________________________________________________________________\n",
      "CPU times: user 1.75 s, sys: 227 ms, total: 1.98 s\n",
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# A simple LSTM with glove embeddings and one dense layer\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                 300,\n",
    "                 weights=[embedding_matrix],\n",
    "                 input_length=max_len,\n",
    "                 trainable=False))\n",
    "\n",
    "model.add(LSTM(100, activation=\"tanh\",\n",
    "    recurrent_activation=\"sigmoid\"))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy', AUC(curve='PR')])\n",
    "    \n",
    "model.summary()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "oI9AlIJVyNRa",
    "outputId": "51a3633f-ce29-4b33-a8cb-7ce694b91580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "callbacks = make_callbacks('glove_lstm_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uUXoA4RrCZ10",
    "outputId": "27226847-489d-47e8-e4f8-ff567a4b7557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "   1/1431 [..............................] - ETA: 3:49 - loss: 0.7461 - accuracy: 0.1300 - auc_1: 0.0350WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "1431/1431 [==============================] - 1117s 781ms/step - loss: 0.1320 - accuracy: 0.9476 - auc_1: 0.7960 - val_loss: 0.1120 - val_accuracy: 0.9549 - val_auc_1: 0.8444\n",
      "Epoch 2/120\n",
      "1431/1431 [==============================] - 1115s 779ms/step - loss: 0.1080 - accuracy: 0.9560 - auc_1: 0.8518 - val_loss: 0.1111 - val_accuracy: 0.9564 - val_auc_1: 0.8548\n",
      "Epoch 3/120\n",
      "1431/1431 [==============================] - 1115s 779ms/step - loss: 0.0995 - accuracy: 0.9594 - auc_1: 0.8716 - val_loss: 0.1048 - val_accuracy: 0.9573 - val_auc_1: 0.8613\n",
      "Epoch 4/120\n",
      "1431/1431 [==============================] - 1116s 780ms/step - loss: 0.0927 - accuracy: 0.9621 - auc_1: 0.8867 - val_loss: 0.1079 - val_accuracy: 0.9565 - val_auc_1: 0.8586\n",
      "Epoch 5/120\n",
      "1431/1431 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9655 - auc_1: 0.9036\n",
      "Epoch 00005: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_allcp-0005.ckpt\n",
      "1431/1431 [==============================] - 1117s 781ms/step - loss: 0.0848 - accuracy: 0.9655 - auc_1: 0.9036 - val_loss: 0.1089 - val_accuracy: 0.9574 - val_auc_1: 0.8591\n",
      "Epoch 6/120\n",
      "1431/1431 [==============================] - 1111s 777ms/step - loss: 0.0765 - accuracy: 0.9694 - auc_1: 0.9198 - val_loss: 0.1078 - val_accuracy: 0.9570 - val_auc_1: 0.8572\n",
      "Epoch 7/120\n",
      "1431/1431 [==============================] - 1117s 781ms/step - loss: 0.0659 - accuracy: 0.9736 - auc_1: 0.9390 - val_loss: 0.1175 - val_accuracy: 0.9533 - val_auc_1: 0.8421\n",
      "Epoch 8/120\n",
      "1431/1431 [==============================] - 1114s 778ms/step - loss: 0.0564 - accuracy: 0.9779 - auc_1: 0.9545 - val_loss: 0.1321 - val_accuracy: 0.9554 - val_auc_1: 0.8349\n",
      "Epoch 9/120\n",
      "1431/1431 [==============================] - 1115s 779ms/step - loss: 0.0452 - accuracy: 0.9829 - auc_1: 0.9700 - val_loss: 0.1396 - val_accuracy: 0.9542 - val_auc_1: 0.8255\n",
      "Epoch 10/120\n",
      "1431/1431 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9872 - auc_1: 0.9808\n",
      "Epoch 00010: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_allcp-0010.ckpt\n",
      "1431/1431 [==============================] - 1117s 781ms/step - loss: 0.0357 - accuracy: 0.9872 - auc_1: 0.9808 - val_loss: 0.1601 - val_accuracy: 0.9532 - val_auc_1: 0.8105\n",
      "Epoch 11/120\n",
      "1431/1431 [==============================] - 1119s 782ms/step - loss: 0.0270 - accuracy: 0.9906 - auc_1: 0.9888 - val_loss: 0.1760 - val_accuracy: 0.9525 - val_auc_1: 0.7975\n",
      "Epoch 12/120\n",
      "1431/1431 [==============================] - 1117s 780ms/step - loss: 0.0204 - accuracy: 0.9930 - auc_1: 0.9935 - val_loss: 0.1997 - val_accuracy: 0.9512 - val_auc_1: 0.7804\n",
      "Epoch 13/120\n",
      "1431/1431 [==============================] - 1116s 780ms/step - loss: 0.0172 - accuracy: 0.9944 - auc_1: 0.9950 - val_loss: 0.2107 - val_accuracy: 0.9499 - val_auc_1: 0.7730\n",
      "Epoch 14/120\n",
      "1431/1431 [==============================] - 1116s 780ms/step - loss: 0.0133 - accuracy: 0.9958 - auc_1: 0.9966 - val_loss: 0.2446 - val_accuracy: 0.9522 - val_auc_1: 0.7638\n",
      "Epoch 15/120\n",
      "1431/1431 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9968 - auc_1: 0.9976\n",
      "Epoch 00015: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_allcp-0015.ckpt\n",
      "1431/1431 [==============================] - 1118s 781ms/step - loss: 0.0107 - accuracy: 0.9968 - auc_1: 0.9976 - val_loss: 0.2470 - val_accuracy: 0.9470 - val_auc_1: 0.7467\n",
      "Epoch 16/120\n",
      "1431/1431 [==============================] - 1118s 781ms/step - loss: 0.0108 - accuracy: 0.9965 - auc_1: 0.9976 - val_loss: 0.2529 - val_accuracy: 0.9509 - val_auc_1: 0.7555\n",
      "Epoch 17/120\n",
      "1431/1431 [==============================] - 1121s 784ms/step - loss: 0.0084 - accuracy: 0.9974 - auc_1: 0.9984 - val_loss: 0.2643 - val_accuracy: 0.9491 - val_auc_1: 0.7460\n",
      "Epoch 18/120\n",
      "1431/1431 [==============================] - 1123s 785ms/step - loss: 0.0089 - accuracy: 0.9973 - auc_1: 0.9984 - val_loss: 0.2671 - val_accuracy: 0.9500 - val_auc_1: 0.7503\n",
      "Epoch 19/120\n",
      "1431/1431 [==============================] - 1119s 782ms/step - loss: 0.0065 - accuracy: 0.9983 - auc_1: 0.9986 - val_loss: 0.2837 - val_accuracy: 0.9497 - val_auc_1: 0.7336\n",
      "Epoch 20/120\n",
      "1431/1431 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9974 - auc_1: 0.9980\n",
      "Epoch 00020: saving model to /content/drive/My Drive/toximeter_project/training/glove_lstm_allcp-0020.ckpt\n",
      "1431/1431 [==============================] - 1126s 787ms/step - loss: 0.0083 - accuracy: 0.9974 - auc_1: 0.9980 - val_loss: 0.2804 - val_accuracy: 0.9488 - val_auc_1: 0.7369\n",
      "Epoch 21/120\n",
      "1431/1431 [==============================] - 1143s 799ms/step - loss: 0.0056 - accuracy: 0.9984 - auc_1: 0.9990 - val_loss: 0.2887 - val_accuracy: 0.9501 - val_auc_1: 0.7378\n",
      "Epoch 22/120\n",
      "1431/1431 [==============================] - 1142s 798ms/step - loss: 0.0051 - accuracy: 0.9986 - auc_1: 0.9991 - val_loss: 0.3128 - val_accuracy: 0.9498 - val_auc_1: 0.7271\n",
      "Epoch 23/120\n",
      "1431/1431 [==============================] - 1144s 799ms/step - loss: 0.0062 - accuracy: 0.9982 - auc_1: 0.9988 - val_loss: 0.3091 - val_accuracy: 0.9504 - val_auc_1: 0.7309\n",
      "Epoch 24/120\n",
      " 575/1431 [===========>..................] - ETA: 10:13 - loss: 0.0036 - accuracy: 0.9991 - auc_1: 0.9994"
     ]
    }
   ],
   "source": [
    "model.fit(xtrain_pad, \n",
    "          ytrain, \n",
    "          epochs=120, \n",
    "          batch_size=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_split=0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QBvukVuo5AI"
   },
   "outputs": [],
   "source": [
    "y_pred=model.predict(\n",
    "    x_valid\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KrifFhZKo5AK"
   },
   "outputs": [],
   "source": [
    "from toxicity.metrics import run_metrics\n",
    "run_metrics(y_pred>.5, y_pred, y_valid_s, visualize=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "GttFyDuOhfnF",
    "sR83aZWlhfnp",
    "tnt5p4qehfnw"
   ],
   "name": "DL_experiments.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0c3691dbb85a44969ace25fbbe5f20a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ae7cc699f854109b10016ee762d0712",
      "max": 354041576,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4ef71166a53f4c9aba0eced4441568e1",
      "value": 354041576
     }
    },
    "109e473e588149a7bf97d483a5f0520e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "385342fbe947406ba8da777e7e887de0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3aa58e9a6ed545918c2eee459eb731cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ef71166a53f4c9aba0eced4441568e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "56d6a79b83a84d5cbc5c3d996dce4168": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "622580b7962f45a9845ce4f6728dfe66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56d6a79b83a84d5cbc5c3d996dce4168",
      "placeholder": "​",
      "style": "IPY_MODEL_a6b2861a7ae9481093c0df5a6f0e4f8a",
      "value": " 354M/354M [00:04&lt;00:00, 76.2MB/s]"
     }
    },
    "6ae7cc699f854109b10016ee762d0712": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96c07cefad0f4fdbbcd2e5611f6bc836": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6b2861a7ae9481093c0df5a6f0e4f8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b47f3ec2b075450ba0240b1cafc5c3d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bc8a03b077ab4fc29fea6620c3b8ec6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f652ba899a05429a8f5d2fd8b3528a0d",
       "IPY_MODEL_e421f8128bbd4eec903a8fba84bf684d"
      ],
      "layout": "IPY_MODEL_3aa58e9a6ed545918c2eee459eb731cb"
     }
    },
    "c5de80398b93435ca8cb59c2e741aae2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0c3691dbb85a44969ace25fbbe5f20a6",
       "IPY_MODEL_622580b7962f45a9845ce4f6728dfe66"
      ],
      "layout": "IPY_MODEL_385342fbe947406ba8da777e7e887de0"
     }
    },
    "e421f8128bbd4eec903a8fba84bf684d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96c07cefad0f4fdbbcd2e5611f6bc836",
      "placeholder": "​",
      "style": "IPY_MODEL_b47f3ec2b075450ba0240b1cafc5c3d6",
      "value": " 411/411 [00:04&lt;00:00, 82.8B/s]"
     }
    },
    "e88ba82b92b7420ab45d28fac47e60ed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f652ba899a05429a8f5d2fd8b3528a0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e88ba82b92b7420ab45d28fac47e60ed",
      "max": 411,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_109e473e588149a7bf97d483a5f0520e",
      "value": 411
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
